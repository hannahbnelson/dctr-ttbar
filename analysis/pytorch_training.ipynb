{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe2b377e-006f-4ff2-a026-129bdad8ec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import awkward as ak\n",
    "import hist\n",
    "from hist import Hist\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import topcoffea.modules.utils as utils\n",
    "import pickle\n",
    "import gzip\n",
    "import logging\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cfdc9c1-c672-47d3-b9e1-096cffb47ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedDataset(Dataset):\n",
    "    def __init__(self, data, weights, targets):\n",
    "        self.data = data\n",
    "        self.weights = weights\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        weights = self.weights[idx]\n",
    "        target = self.targets[idx]\n",
    "        return sample, weights, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab3b0a11-0011-4066-859f-d201f100bb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.main_module= nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.LeakyReLU(),\n",
    "            # nn.Linear(128,128),\n",
    "            # nn.LeakyReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.main_module(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10b224cb-829b-4c44-a5e5-c0f8a1758068",
   "metadata": {},
   "outputs": [],
   "source": [
    "fSMEFT = \"/afs/crc.nd.edu/user/h/hnelson2/dctr/analysis/dctr_SMEFT.pkl.gz\"\n",
    "fpowheg = \"/afs/crc.nd.edu/user/h/hnelson2/dctr/analysis/dctr_powheg_skimmed.pkl.gz\"\n",
    "\n",
    "inputs_smeft = pickle.load(gzip.open(fSMEFT)).get()\n",
    "inputs_powheg = pickle.load(gzip.open(fpowheg))\n",
    "\n",
    "assert inputs_smeft.shape == inputs_powheg.shape, f\"SMEFT and Powheg inputs are not the same shape.\\n SMEFT shape: {inputs_smeft.shape} \\n Powheg shape:{inputs_powheg.shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42c35c2e-cb4a-4cd4-9f8e-3336c2e0cb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "rando = 1234\n",
    "\n",
    "smeft_train = inputs_smeft.sample(frac=0.7, random_state=rando)\n",
    "smeft_test = inputs_smeft.drop(smeft_train.index)\n",
    "powheg_train = inputs_powheg.sample(frac=0.7, random_state=rando)\n",
    "powheg_test = inputs_powheg.drop(powheg_train.index)\n",
    "truth_smeft = np.ones_like(smeft_train['weights'])\n",
    "truth_powheg = np.zeros_like(powheg_train['weights'])\n",
    "\n",
    "weights_smeft = np.ones_like(smeft_train['weights'])\n",
    "weights_powheg = np.ones_like(powheg_train['weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3530fdcf-5bed-4821-b998-dc0a130d8ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.from_numpy(np.concatenate([smeft_train, powheg_train], axis=0).astype(np.float32))\n",
    "w = torch.from_numpy(np.concatenate([weights_smeft, weights_powheg], axis=0).astype(np.float32))\n",
    "y = torch.from_numpy(np.concatenate([truth_smeft, truth_powheg], axis=0).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3580b5d-a063-42d9-b8cd-8c08641cbf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_z = torch.from_numpy(np.concatenate([smeft_test, powheg_test], axis=0).astype(np.float32))\n",
    "test_y = torch.from_numpy(np.concatenate([np.ones_like(smeft_test['weights']), np.zeros_like(powheg_test['weights'])], axis=0).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f79f5709-af99-466e-8413-a245b107e78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = WeightedDataset(z, w, y)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd8cbe4b-2f24-4635-bf47-56128cf02307",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = z.shape[1]\n",
    "model = NeuralNetwork(input_dim)\n",
    "\n",
    "loss_fn = nn.BCELoss(reduction='mean')\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "trainLoss = []\n",
    "testLoss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8584a0-bfcd-4798-ba15-43312d3ac152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "    TrainLoss: 0.0008219547967386761\n",
      "    TrainLossEnd: 0.00018521766469348222\n",
      "    TestLoss: 9.620402124710381e-05\n",
      "--------------------\n",
      "Epoch 2/10\n",
      "    TrainLoss: 0.00010819627537211628\n",
      "    TrainLossEnd: 0.0\n",
      "    TestLoss: 0.0\n",
      "--------------------\n",
      "Epoch 3/10\n",
      "    TrainLoss: 0.0\n",
      "    TrainLossEnd: 0.0\n",
      "    TestLoss: 0.0\n",
      "--------------------\n",
      "Epoch 4/10\n",
      "    TrainLoss: 0.0\n",
      "    TrainLossEnd: 0.0\n",
      "    TestLoss: 0.0\n",
      "--------------------\n",
      "Epoch 5/10\n",
      "    TrainLoss: 0.0\n",
      "    TrainLossEnd: 0.0\n",
      "    TestLoss: 0.0\n",
      "--------------------\n",
      "Epoch 6/10\n",
      "    TrainLoss: 0.0\n",
      "    TrainLossEnd: 0.0\n",
      "    TestLoss: 0.0\n",
      "--------------------\n",
      "Epoch 7/10\n",
      "    TrainLoss: 0.0\n",
      "    TrainLossEnd: 0.0\n",
      "    TestLoss: 0.0\n",
      "--------------------\n",
      "Epoch 8/10\n",
      "    TrainLoss: 0.0\n",
      "    TrainLossEnd: 0.0\n",
      "    TestLoss: 0.0\n",
      "--------------------\n",
      "Epoch 9/10\n",
      "    TrainLoss: 0.0\n",
      "    TrainLossEnd: 0.0\n",
      "    TestLoss: 0.0\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "nepochs = 10\n",
    "\n",
    "trainLoss = []\n",
    "trainLossEnd = []\n",
    "testLoss = []\n",
    "\n",
    "for epoch in range(nepochs):\n",
    "    epoch_loss = 0.0\n",
    "    model.train()   # sets the model in training mode. Crucial for layers that behave differently during training vs evaluation (e.g. dropout, mean, variance)\n",
    "    for batch_samples, batch_weights, batch_targets in train_dataloader:\n",
    "        optimizer.zero_grad()                       # clear the gradients from the previous batch\n",
    "        # forward pass\n",
    "        outputs = model(batch_samples).squeeze(1)   # perform the forward pass to get the model's predictions\n",
    "        loss = loss_fn(outputs, batch_targets)     # calculate the loss\n",
    "        # backward pass\n",
    "        loss.backward()                             # calculate the gradients of the loss w.r.t. the model's parameters\n",
    "        optimizer.step()                            # update the model's parameters using the calculated gradients\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    trainLoss_epoch = epoch_loss / len(train_dataloader)\n",
    "    trainLossEnd_epoch = loss_fn(model(z).squeeze(1), y)\n",
    "    testLoss_epoch = loss_fn(model(test_z).squeeze(1), test_y)\n",
    "\n",
    "    trainLossEnd.append(trainLossEnd_epoch)\n",
    "    trainLoss.append(trainLoss_epoch)\n",
    "    testLoss.append(testLoss_epoch)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{nepochs}\")\n",
    "    print(f\"    TrainLoss: {trainLoss_epoch}\")\n",
    "    print(f\"    TrainLossEnd: {trainLossEnd_epoch}\")\n",
    "    print(f\"    TestLoss: {testLoss_epoch}\")\n",
    "    print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fada56-a579-45ff-a13e-8557dca37bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
